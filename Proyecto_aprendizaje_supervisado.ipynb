{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 30px; color: red; font-family: 'Arial', sans-serif;\">\n",
    "    <b>Predicción del Abandono de Clientes en Beta Bank usando Modelos de Aprendizaje Supervisado</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contenido <a id='back'></a>\n",
    "\n",
    "* [Introducción](#intro)\n",
    "* [Etapa 1. Carga y Exploración de los Datos](#data_review)\n",
    "    * [1.1 Descripción de los Datos](#data_review)\n",
    "* [Etapa 2. Preparación de los Datos](#data_preparing)\n",
    "    * [2.1 División del conjunto de entrenamiento y de prueba](#data_divisions)\n",
    "    * [2.2 Escalamiento de los datos](#data_scaler)\n",
    "    * [2.3 Codificación One-Hot Encoding de las variables categóricas](#data_one-hot)\n",
    "    * [Conclusiones de la Etapa 2](#conclusions_etapa2)\n",
    "* [Etapa 3. Desarrollo del Modelo](#data_model)\n",
    "    * [3.1 Equilibrio de Clases](#class_balance)\n",
    "    * [3.2 Entrenamiento de los 4 modelos con desequilibrio de clases](#no_balance_class)\n",
    "    * [3.3 Equilibrio de la clase minoritaria (oversampling](#train_oversampling)\n",
    "    * [3.4 Equilibrio de la clase mayoritaria (undersampling)](#train_undersampling)\n",
    "* [Etapa 4. Selección del mejor modelo](#model_evaluation)\n",
    "    * [4.1 Modelo con mejores resultados en las métricas](#good_model)\n",
    "* [Conclusiones finales del proyecto](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción <a id='intro'></a>\n",
    "\n",
    "En el competitivo mundo de la banca, retener a los clientes existentes es significativamente más económico que adquirir nuevos. Beta Bank ha identificado que un número creciente de sus clientes está abandonando el servicio mes tras mes. Con el objetivo de mitigar esta pérdida, el banco busca predecir cuáles de sus clientes están en riesgo de irse. Esto permitiría implementar estrategias de retención efectivas.\n",
    "\n",
    "Este proyecto de Data Science se centrará en la creación de un modelo predictivo basado en el comportamiento histórico de los clientes. Utilizando técnicas de aprendizaje supervisado, se espera que el modelo pueda identificar con precisión los clientes propensos a abandonar el banco. El éxito del proyecto será evaluado con la métrica F1, con una meta mínima de 0.59, y se complementará con el análisis de la métrica AUC-ROC para evaluar el desempeño general del modelo.\n",
    "\n",
    "El proyecto abordará varios desafíos clave, entre ellos el desequilibrio de clases, que será corregido mediante al menos dos enfoques diferentes para garantizar la calidad del modelo. Al finalizar, el modelo se probará en un conjunto de prueba para confirmar su eficacia en un entorno real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1: Carga y exploración de datos <a id='data_review'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los módulos a utilizar, e importamos funciones específicas de módulos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el conjunto de datos, el cual llamaremos `data`\n",
    "data = pd.read_csv('/home/josue/Aprendizaje_supervisado/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de los datos <a id='data_review'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observación de todo el conjunto de datos: \n",
      "    RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "\n",
      "\n",
      "Dimensiones del conjunto de datos: (10000, 14)\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "\n",
      "Conteo de miembros activos del Banco: IsActiveMember\n",
      "1    5151\n",
      "0    4849\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Revisamos a detalle el conjunto de datos\n",
    "\n",
    "print('Observación de todo el conjunto de datos:', '\\n', data.head())\n",
    "print('\\n')\n",
    "print(f'Dimensiones del conjunto de datos:', data.shape)\n",
    "print('\\n')\n",
    "print(data.info())\n",
    "print('\\n')\n",
    "print('Conteo de personas que han abandonado el Banco:', data['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analizar el conjunto de datos, vemos dos cosas que corregir.  \n",
    "    1.  Normalizar los títulos de las observaciones.   \n",
    "    2.  Tratar los valores faltantes en la observación `Tenure` mediante un modelo que es KNN Imputer y imputará los valores faltantes.  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   rownumber        10000 non-null  int64  \n",
      " 1   customerid       10000 non-null  int64  \n",
      " 2   surname          10000 non-null  object \n",
      " 3   creditscore      10000 non-null  int64  \n",
      " 4   geography        10000 non-null  object \n",
      " 5   gender           10000 non-null  object \n",
      " 6   age              10000 non-null  int64  \n",
      " 7   tenure           9091 non-null   float64\n",
      " 8   balance          10000 non-null  float64\n",
      " 9   numofproducts    10000 non-null  int64  \n",
      " 10  hascrcard        10000 non-null  int64  \n",
      " 11  isactivemember   10000 non-null  int64  \n",
      " 12  estimatedsalary  10000 non-null  float64\n",
      " 13  exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# 1. Normalizar las Observaciones del conjunto de datos\n",
    "\n",
    "data.columns = data.columns.str.lower()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 2. Imputar valores faltantes en `tenure`\n",
    "\n",
    "# Creamos el Objeto KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5) # Seleccionamos un total de 5 vecinos\n",
    "\n",
    "# Seleccionamos las características relevantes para la imputación\n",
    "columns = ['creditscore', 'age', 'balance', 'numofproducts', 'hascrcard', 'isactivemember', 'estimatedsalary', 'tenure']\n",
    "\n",
    "# Aplicar KNN imputer\n",
    "data[columns] = imputer.fit_transform(data[columns])\n",
    "\n",
    "# Verificamos que no haya valores ausentes en `tenure`\n",
    "print(data['tenure'].isnull().sum())\n",
    "\n",
    "# Verificamos que no haya observaciones duplicadas\n",
    "print(data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de realizar estas correcciones al conjunto de datos, hemos visto que la calidad de los datos es mejor, ahora pasemos a la siguiente etapa que será donde nos encargaremos de la preparación de los datos, para después utilizar el modelo de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2. Preparación de los datos <a id='data_preparing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 División del conjunto de entrenamiento y de prueba <a id='data_divisions'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos nuestro conjunto de datos en `features` y `target`, cabe destacar que en `features` eliminaremos características que no son de mucha utilidad para el modelo.\n",
    "features = data.drop(columns=['rownumber', 'customerid', 'surname', 'exited'], axis=1)\n",
    "target = data['exited']\n",
    "\n",
    "# Dividimos nuestro conjunto de datos en entrenamiento y prueba (80% para entrenamiento y 20% para prueba)\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Escalamiento del conjunto de datos con Scaler <a id='data_scaler'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para que un modelo funcione bien y sin priorizar cierto tipo de características, es importante escalarlo, con esto el modelo evaluará por igual todas las características\n",
    "\n",
    "# Seleccionamos las características a escalar\n",
    "numerical_columns_scale = ['creditscore', 'age', 'tenure', 'balance', 'numofproducts','estimatedsalary']\n",
    "\n",
    "# Creamos un objeto Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicación de scaler en nuestro conjunto de entrenamiento y prueba\n",
    "features_train[numerical_columns_scale] = scaler.fit_transform(features_train[numerical_columns_scale])\n",
    "features_test[numerical_columns_scale] = scaler.transform(features_test[numerical_columns_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Codificación de variables categóricas (One-Hot Encoding) <a id='data_one-hot'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la codificación One-Hot Encoding y convertimos las variables categóricas en binarias\n",
    "features_train = pd.get_dummies(features_train, drop_first=True)\n",
    "features_test = pd.get_dummies(features_test, drop_first=True)\n",
    "\n",
    "# Utilizamos `align` para asegurarnos que tanto el conjunto de entrenamiento como de prueba tengan las mismas columnas\n",
    "features_train, features_test = features_train.align(features_test, join='Left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones de la Etapa 2 <a id='conclusions_etapa2'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección de preparación de los datos, nos encargamos primero de segmentar los datos, en `features` y el `target` eliminando algunas columnas para `features`. Posteriormente dividimos nuestro conjunto de datos, con la ayuda de la función `train_test_split`, una vez haciendo esto, reservamos el 80% del conjunto de datos para el entrenamiento y el otro 20% para prueba. Debido a que nuestro conjunto hay variables numéricas con diferentes valores, era necesario escalaras con la media y una desviación estándar de 1, con `StandardScaler` realizamos esto y escalamos todas las variables numéricas.\n",
    "\n",
    "Finalmente, asi como tuvimos que tratar de una forma las variables numéricas, las categóricas por su parte también lo necesita. Para las categóricas utilizaremos la codificación One-Hot Encoding, lo que ayudara a que las variables categóricas se conviertas a variables binarias, esto con el propósito, de que nuestro modelo de ML, trabaje sin ningún problema.\n",
    "\n",
    "Para finalizar, con la ayuda de la función `align`, nos aseguramos que tanto el conjunto de entrenamiento tenga la misma dimensión de datos, para que el modelo de ML, trabaje sin ningún problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3: Desarrollo del Modelo <a id='data_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Equilibrio de las clases <a id='class_balance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exited\n",
      "0    0.79875\n",
      "1    0.20125\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Observación del equilibrio de nuestras clases\n",
    "print(target_train.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos tenemos un desequilibrio de clases, puesto que para los clientes que no abandonaron el banco es de un 80%, pero de los que si un 20%, lo cual nos muestra el gran desequilibrio que tienen estas clases, de seguir así el modelo podría anteponer la mayoría de clases y sesgarse hacia esa clase y la minoría relegarla. Con esto el resultado sería que el modelo tendrá sesgo y no será preciso en sus predicciones. Ahora que tenemos listos los datos y la información de clase dominante, veamos lo que sigue. \n",
    "\n",
    "Primero para ver como el desequilibrio de clases sesga el resultado de modelo, el entrenamiento y las predicciones las haremos sin tratar este desequilibrio de clases, una vez que veamos los resultados seguiremos adelante con obtener los mismos resultados pero corrigiendo el desequilibrio de clases con la función `resample` de dos formas, una mediante el `oversampling` y otra mediante el `undersampling`\n",
    "\n",
    "A continuación, entrenaremos nuestro conjunto de datos con 4 modelos, haremos una función que reciba los parámetros de entrenamiento y prueba, después iniciaremos los modelos y con la ayuda de un diccionario y dos ciclos obtendremos las métricas F1 Score y AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Entrenamiento de los 4 modelos con desequilibrio de clases <a id='no_balance_class'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta sección vamos a utilizar 4 Modelos, de los cuales escogeremos el que de la mayor tasa de éxito, también, veremos que parámetros deben ser cambiados para ajustarlo lo máximo posible, los modelos de ML a utilizar son:\n",
    "# 1. LogisticRegression\n",
    "# 2. RandomForestClassifier\n",
    "# 3. GradientBoostingClassifier\n",
    "# 4. SVC\n",
    "\n",
    "# Creamos una función llamada `train_and_evaluate_model` que se encargará de entrenar el modelo, hacer las predicciones y darnos el resultado de las métricas F1 y AUC-ROC.\n",
    "def train_and_evaluate_model(model, features_train, features_test, target_train, target_test):\n",
    "    # Entrenar el modelo\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    # Predecir con el modelo\n",
    "    predictions = model.predict(features_test)\n",
    "\n",
    "    # Calcula F1 Score\n",
    "    f1 = f1_score(target_test, predictions)\n",
    "\n",
    "    # Calcula AUC-ROC\n",
    "    proba = model.predict_proba(features_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    auc_score = roc_auc_score(target_test, proba) if proba is not None else 'N/A'\n",
    "    return f1, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Logistic Regression\n",
      "F1 Score: 0.2857142857142857\n",
      "AUC-ROC: 0.7576119856298695\n",
      "\n",
      "\n",
      "Modelo: Random Forest\n",
      "F1 Score: 0.564179104477612\n",
      "AUC-ROC: 0.8608113198277133\n",
      "\n",
      "\n",
      "Modelo: SVM Model\n",
      "F1 Score: 0.49752883031301476\n",
      "AUC-ROC: 0.8468640152693805\n",
      "\n",
      "\n",
      "Modelo: Gradient Boosting\n",
      "F1 Score: 0.5832106038291606\n",
      "AUC-ROC: 0.8776394991000058\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos los 4 modelos de ML\n",
    "\n",
    "logistic_reg = LogisticRegression(random_state=12345) # Modelo 1\n",
    "random_forest = RandomForestClassifier(random_state=12345) # Modelo 2\n",
    "svm_model = SVC(probability=True, random_state=12345) # Modelo 3, agregamos `probability=True` para poder calcular AUC-ROC\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=12345) # Modelo 4\n",
    "\n",
    "# Lista de Modelos\n",
    "models = {\n",
    "    'Logistic Regression': logistic_reg,\n",
    "    'Random Forest': random_forest,\n",
    "    'SVM Model': svm_model,\n",
    "    'Gradient Boosting': gradient_boosting\n",
    "}\n",
    "\n",
    "# Variable para almacenar los resultados\n",
    "results = {}\n",
    "\n",
    "# Entrenar y evaluar cada Modelo\n",
    "for model_name, model in models.items():\n",
    "    f1, auc_score = train_and_evaluate_model(model, features_train, features_test, target_train, target_test)\n",
    "    results[model_name] = {'F1 Score': f1, 'AUC-ROC': auc_score}\n",
    "\n",
    "# Mostrar los resultados\n",
    "for model_name, result in results.items():\n",
    "    print(f'Modelo: {model_name}')\n",
    "    print(f\"F1 Score: {result['F1 Score']}\")\n",
    "    print(f\"AUC-ROC: {result['AUC-ROC']}\")\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de probar los 4 Modelos de ML, observamos distintos resultados de F1 Score y AUC-ROC, ahora tenemos que ver el desequilibrio de las clases, ya que ocupamos un nivel más alto de F1 Score, con estos resultados, podemos darnos cuenta que el desequilibrio de las clases se está haciendo presente en los resultados de las métricas, por esta razón tenemos que equilibrarlas y entrenar nuevamente los modelos de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Equilibrio de la clase minoritaria (oversampling) <a id='train_oversampling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incremento de la clase minoritaria con `resample` (oversampling) \n",
    "\n",
    "# Combinar `features_train` y `features_test` en un solo DF\n",
    "train_data = pd.concat([features_train, target_train], axis=1)\n",
    "\n",
    "# Separar las clases: clase mayoritaria (clientes que no se van) y clase minoritaria (clientes que se van)\n",
    "class_majority = train_data[train_data['exited'] == 0] # Clientes que no se van\n",
    "class_minority = train_data[train_data['exited'] == 1] # Clientes que se van\n",
    "\n",
    "# Aumentar la clase minoritaria (ovsersampling) con `resample`\n",
    "class_minority_ovsersampling = resample(class_minority, replace=True, n_samples= len(class_majority), random_state=12345)\n",
    "\n",
    "# Combinar ambas clases mayoritaria y minoritaria\n",
    "class_train = pd.concat([class_majority, class_minority_ovsersampling])\n",
    "\n",
    "# Separar el conjunto de datos en train y test\n",
    "features_train_oversampling = class_train.drop(columns='exited')\n",
    "target_train_oversampling = class_train['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo con equilibrio de clases (oversampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como previamente realizamos una función para entrenar los 4 modelos propuestos para la resolución del problema, ahora la usaremos nuevamente, solo crearemos un nuevo diccionario que es donde guardaremos los resultados de evaluación del modelo con (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Logistic Regression\n",
      "F1 Score: 0.5016835016835017\n",
      "AUC-ROC: 0.7628556242565184\n",
      "\n",
      "\n",
      "Modelo: Random Forest\n",
      "F1 Score: 0.5915875169606513\n",
      "AUC-ROC: 0.8467888296502306\n",
      "\n",
      "\n",
      "Modelo: SVM Model\n",
      "F1 Score: 0.6115384615384616\n",
      "AUC-ROC: 0.8580242410346732\n",
      "\n",
      "\n",
      "Modelo: Gradient Boosting\n",
      "F1 Score: 0.6302439024390243\n",
      "AUC-ROC: 0.8756601074037735\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variable para almacenar los resultados\n",
    "results_oversampling = {}\n",
    "\n",
    "# Entrenar y evaluar cada Modelo\n",
    "for model_name, model in models.items():\n",
    "    f1, auc_score = train_and_evaluate_model(model, features_train_oversampling, features_test, target_train_oversampling, target_test)\n",
    "    results_oversampling[model_name] = {'F1 Score': f1, 'AUC-ROC': auc_score}\n",
    "\n",
    "# Mostrar los resultados\n",
    "for model_name, result in results_oversampling.items():\n",
    "    print(f'Modelo: {model_name}')\n",
    "    print(f\"F1 Score: {result['F1 Score']}\")\n",
    "    print(f\"AUC-ROC: {result['AUC-ROC']}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de aplicar resample y realizar un oversampling, vemos que los resultados de las métricas suben en una cantidad considerable, claramente, el modelo está evaluando mejor, debido a que las clases están parejas, entonces nuestros modelos no se están sesgando hacia uno o otro lado, sin duda, el evaluar el desequilibrio de las clases es un punto muy importante a tomar en cuenta, cuando se resuelven problemas de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Equilibrio de la clase mayoritaria (undersampling)<a id='train_undersampling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decremento con la clase mayoritaria con `resample` (unsersampling)\n",
    "\n",
    "# Como anteriormente ya concatenamos los conjuntos de datos de entrenamiento y después obtuvimos la clase mayoritaria y minoritaria, utilizaremos esos mismas variables para no redundar en código.\n",
    "\n",
    "# Decrementando el conjunto con la clase mayoritaria\n",
    "class_majority_undersampling = resample(class_majority, replace=False, n_samples= len(class_minority), random_state=12345)\n",
    "\n",
    "# Concatenación de la clase mayoritaria con la minoritaria del mismo tamaño\n",
    "class_minority_train = pd.concat([class_minority, class_majority_undersampling])\n",
    "\n",
    "# Separar el conjunto de datos en train y test\n",
    "features_train_undersampling = class_minority_train.drop(columns='exited')\n",
    "target_train_undersampling = class_minority_train['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo con equilibrio de clases (undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Logistic Regression\n",
      "F1 Score: 0.5016501650165017\n",
      "AUC-ROC: 0.7597231382626315\n",
      "\n",
      "\n",
      "Modelo: Random Forest\n",
      "F1 Score: 0.6007194244604317\n",
      "AUC-ROC: 0.8594468125019541\n",
      "\n",
      "\n",
      "Modelo: SVM Model\n",
      "F1 Score: 0.6145354185832567\n",
      "AUC-ROC: 0.8651616639694136\n",
      "\n",
      "\n",
      "Modelo: Gradient Boosting\n",
      "F1 Score: 0.6232558139534883\n",
      "AUC-ROC: 0.875363831399599\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variable para almacenar los resultados\n",
    "results_undersampling = {}\n",
    "\n",
    "# Entrenar y evaluar cada Modelo\n",
    "for model_name, model in models.items():\n",
    "    f1, auc_score = train_and_evaluate_model(model, features_train_undersampling, features_test, target_train_undersampling, target_test)\n",
    "    results_undersampling[model_name] = {'F1 Score': f1, 'AUC-ROC': auc_score}\n",
    "\n",
    "# Mostrar los resultados\n",
    "for model_name, result in results_undersampling.items():\n",
    "    print(f'Modelo: {model_name}')\n",
    "    print(f\"F1 Score: {result['F1 Score']}\")\n",
    "    print(f\"AUC-ROC: {result['AUC-ROC']}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de utilizar la función resample y hacer un undersampling, nos damos cuenta que los resultados siguen siendo muy favorables en las métricas, lo cual nos deja ver que ocupar una u otra técnica es de gran ayuda, el undersampling la ventaja pueden ser sus tiempos de ejecución, en modelos con miles de datos o cientos de miles, hacer un oversampling ocupará muchos recursos y el tiempo será mayor, debido a que la clase minoritaria se le pasarán los mismos datos que la mayoritaria, men cambio con undersampling, puede que se ahorren mas recursos y tiempos debido, a que el conjunto de datos se reduce a la clase minoritaria, más sin embargo, aquí entra la evaluación de los Científicos de Datos, generalmente siempre se busca llegar al valor máximo de las métricas, entonces siempre debemos ver la forma, de obtener las mejores métricas para que el modelo sea lo más confiable posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4. Selección del mejor modelo <a id='model_evaluation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de analizar varios modelos, y de ajustas el desequilibrio de clases, tenemos que escoger cual es el mejor modelo que genere los mejores resultados en las métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.1 Modelo con mejores resultados en las métricas<a id='good_model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejor F1 Score: 0.6302439024390243, Modelo: Gradient Boosting, Categoría: Resultados sin desequilibrio de clases (oversampling)\n",
      "\n",
      "Mejor AUC-ROC: 0.8776394991000058, Modelo: Gradient Boosting, Categoría: Resultados con desequilibrio de clases\n"
     ]
    }
   ],
   "source": [
    "# Selección del mejor modelo con sus mejores métricas de evaluación\n",
    "\n",
    "# Concatenar los diccionarios con los resultados de las métricas de los modelos\n",
    "results_final = {'Resultados con desequilibrio de clases': results,\n",
    "                 'Resultados sin desequilibrio de clases (oversampling)': results_oversampling,\n",
    "                 'Resultados sin desequilibrio de clases (undersampling)': results_undersampling}\n",
    "\n",
    "# Inicializar variables para guardar el mejor modelo\n",
    "best_f1_score = 0\n",
    "best_auc_roc = 0\n",
    "best_f1_model = ''\n",
    "best_auc_roc_model = ''\n",
    "best_f1_category = ''\n",
    "best_auc_roc_category = ''\n",
    "\n",
    "# Bucle para encontrar la mejores métricas en cada categoría y modelo\n",
    "for category, models in results_final.items():\n",
    "    for model, metric in models.items():\n",
    "        # Comparar F1 Score\n",
    "        if metric['F1 Score'] > best_f1_score:\n",
    "            best_f1_score = metric['F1 Score']\n",
    "            best_f1_model = model\n",
    "            best_f1_category = category\n",
    "        # Comparar AUC-ROC\n",
    "        if metric['AUC-ROC'] > best_auc_roc:\n",
    "            best_auc_roc = metric['AUC-ROC']\n",
    "            best_auc_roc_model = model\n",
    "            best_auc_roc_category = category\n",
    "\n",
    "# Imprimir los mejores resultados\n",
    "print(f\"\\nMejor F1 Score: {best_f1_score}, Modelo: {best_f1_model}, Categoría: {best_f1_category}\")\n",
    "print(f\"\\nMejor AUC-ROC: {best_auc_roc}, Modelo: {best_auc_roc_model}, Categoría: {best_auc_roc_category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interesante ver los resultados de las métricas finales, el valor F1 Score sin duda sería cuando no existiera desequilibrio de clases, pero el mejor resultado de AUC-ROC fue con desequilibrio, lo cual es entendible debido a que AUC-ROC no se fija en precisión, sino solo en que tan bien el modelo esta asignando las probabilidades, en cambio F1 Score mide que tan bien el modelo esta detectando los verdaderos positivos y los falsos positivos, f1 score, sin duda es sensible a un desequilibrio de las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones finales del proyecto <a id='conclusions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este proyecto, el objetivo fue desarrollar un modelo de Machine Learning para predecir si un cliente de Beta Bank abandonaría el banco en el futuro. Esto permitiría a la institución implementar estrategias de retención antes de perder a esos clientes.\n",
    "\n",
    "#### 1. Preparación de los datos\n",
    "Se llevó a cabo una serie de pasos para preparar los datos de manera efectiva:\n",
    "\n",
    "- **Limpieza y preprocesamiento**: Se manejaron los datos faltantes y se codificaron las variables categóricas usando técnicas como **One-Hot Encoding**.\n",
    "- **Escalado de características**: Las características numéricas se escalaron utilizando **StandardScaler** para garantizar que todas las características estuvieran en la misma escala.\n",
    "- **Manejo del desequilibrio de clases**: El conjunto de datos estaba altamente desequilibrado, ya que había más clientes que no se iban del banco en comparación con los que se iban. Para abordar esto, se aplicaron dos técnicas:\n",
    "  - **Sobremuestreo (Oversampling)** de la clase minoritaria.\n",
    "  - **Submuestreo (Undersampling)** de la clase mayoritaria.\n",
    "\n",
    "#### 2. Modelos de Machine Learning probados\n",
    "Se probaron varios modelos para encontrar el que mejor predijera el abandono de clientes:\n",
    "\n",
    "- **Regresión Logística**\n",
    "- **Random Forest**\n",
    "- **Support Vector Machine (SVM)**\n",
    "- **Gradient Boosting**\n",
    "\n",
    "De todos los modelos probados, el **Gradient Boosting** fue el que arrojó los mejores resultados. Se obtuvo un **F1 Score de 0.6302** y un **AUC-ROC de 0.8757** cuando se aplicó la técnica de sobremuestreo para corregir el desequilibrio de clases.\n",
    "\n",
    "#### 3. Comparación de métricas\n",
    "- **F1 Score**: Esta métrica mejoró notablemente cuando se equilibraron las clases mediante el **sobremuestreo**, ya que el modelo pudo prestar más atención a la clase minoritaria (clientes que se van). Esto es clave en conjuntos de datos desequilibrados, donde un modelo que solo prediga la clase mayoritaria no sería útil.\n",
    "\n",
    "- **AUC-ROC**: El **AUC-ROC** fue consistente y alto en todas las pruebas, incluso en el conjunto de datos desequilibrado. Esto refleja que el modelo es capaz de distinguir bien entre clientes que se van y los que se quedan, basándose en las probabilidades asignadas a cada clase.\n",
    "\n",
    "#### 4. Resultados\n",
    "El modelo de **Gradient Boosting** no solo superó el valor mínimo de F1 Score requerido (**0.59**), sino que también mostró una excelente capacidad para distinguir entre clientes que se quedan y clientes que abandonan el banco, lo que sugiere que este modelo puede ser utilizado de manera efectiva en un entorno real.\n",
    "\n",
    "#### 5. Conclusión general\n",
    "El proyecto demostró que es posible construir un modelo efectivo para predecir el abandono de clientes utilizando técnicas avanzadas de Machine Learning y estrategias para manejar el desequilibrio de clases. El uso de **Gradient Boosting**, en particular, resultó ser una excelente opción por su capacidad para corregir los errores progresivamente y mejorar las predicciones.\n",
    "\n",
    "A futuro, **Beta Bank** puede utilizar este modelo para identificar clientes en riesgo y tomar acciones proactivas para mejorar la retención, lo que será clave para reducir la pérdida de clientes y mejorar la rentabilidad.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
